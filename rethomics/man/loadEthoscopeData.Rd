% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ethoscope_io.R
\name{loadEthoscopeData}
\alias{loadEthoscopeData}
\title{Read data from a result file.}
\usage{
loadEthoscopeData(what, min_time = 0, max_time = Inf,
  reference_hour = NULL, verbose = TRUE, cache_files = TRUE,
  n_cores = 1, FUN = NULL, ...)
}
\arguments{
\item{what}{an object describing which file(s) to load and, optionally, associated variables/conditions (see details).}

\item{min_time}{exclude data before min_time (in seconds). This time is relative to the start of the experiment.}

\item{max_time}{exclude data after max_time (in seconds). It is also relative to the start of the experiment.}

\item{reference_hour}{the hour, in the day, to use as t_0 reference. When unspecified, time will be relative to the start of the experiment.}

\item{verbose}{whether to print progress (a logical).}

\item{cache_files}{whether SQL files should be cached in a tmp dir for faster reading}

\item{n_cores}{how many cores should be used to read/convert data}

\item{FUN}{an optional function to transform the data from each `region' (i.e. a data.table) immediately after is has been loaded.}

\item{...}{extra arguments to be passed to \code{FUN}}
}
\value{
A data.table where every row is an individual measurement. That is a position at a unique time (\code{t}) in a 
unique region (\code{region_id}), and from a unique result file/experiment (\code{experiment_id}).
The time is expressed in seconds. Distance units (e.g. xy position, height/width) are expressed as a fraction of the width of the region they originate from.
}
\description{
This function is used to convert all the information
contained in a result file generated by the ethoscope platform \href{http://gilestrolab.github.io/ethoscope/}
(i.e a .db file) into an R `data.table'.
}
\details{
\code{what} can be one of two objects:
\itemize{
 \item{A character vector. }{In which case, it is assumed that each element is the path to a different file to load.}
 \item{A dataframe. }{The dataframe \emph{must} have a column named `path'. 
 The path basename will be used as a unique identifier for a specific experiment (\code{experiment_id}).
Arbitrary column can be added to map experimental conditions to file name.
In addition, the dataframe can have a column named \code{region_id}. When defined, only the specified combinations of \code{path} and \code{region_id}
will be loaded. This allows to map additional conditions (i.e. data frame columns) to specific regions/files.
When additional conditions are provided, they will result in creation of custom columns in the output of this function.}
}
}
\examples{

# First of all, let us load files from the data sample included within this package.
# Most likely, you will already have your own data files.
sample_files <- c("tube_monitor_validation_subset.db",
                  "monitor_validation_subset.db")
# Extract the files in your computer
paths <- sapply(sample_files, loadSampleData)
# Now, `paths` is just a vector of file names:
print(paths)
#################
#################
# Case 1: load ALL REGIONS from a SINGLE FILE
validation_data_file <- paths[1]
# `validation_data_file` is simply the path to the .db file in your computer
dt <- loadEthoscopeData(validation_data_file)
print(dt)
###############
# Case 2: load ALL REGIONS from MULTIPLE FILES
# we pass all the files we want to load as the `what` argument
dt <- loadEthoscopeData(paths)
# Note the column `experiment_id` in dt. It tells us which file/experiment 
# each measurement originates from.
print(dt)

###############
# Case 3: load ALL REGIONS from MULTIPLE FILES AND add CONDITIONS
# Let us imagine that each file/experiment
# was acquired under different experimental condition.
# We can encode this information in a 'master-table' (i.e a data.frame) 
# in which a column named \\code{path} maps experimental condition(s). 
# For instance, 2 different treatments:
master_table <- data.frame(path=paths, treatment=c("control", "drug_A"))
# Let us check our table:
print(master_table)
# The table looks OK, so we load the actual data
dt <- loadEthoscopeData(master_table)
# Note that `dt` now contains a column for your treatment.
print(colnames(dt))
# This makes it easier to perform things such as average per treatment.
print(dt[,.(mean_x = mean(x)),by="treatment"])
###############
# Case 4: load SELECTED REGIONS from MULTIPLE FILE, WITH CONDITIONS
# Sometimes, different regions contain different conditions.
# If the master table has a column named `region_id`, 
# only the specified regions will be returned.
# Let us assume that we want to replicate case 3, 
# but, now, we load only the first 20 regions.
master_table <- data.table(path=paths, 
                           treatment=c("control", "drug_A"), 
                           region_id=rep(1:20,each= 2))
# We could also imagine that every even region contains a male,
# whilst every odd one has a female:
master_table[, sex := ifelse(region_id \%\% 2, "male", "female" )]
# Note that we have now two conditions.
# Let us check our new table:
print(master_table)
# Then we can load our data:
dt <- loadEthoscopeData(master_table)
# This is simply a subset of data, so many regions are missing
# lets display the regions we ended up with
print(dt[,.(NA),by=key(dt)])
####################
# Case 5: Apply ANALYSIS/function whist loading the data.
# You can also apply a function from this package,
# or your own function to the data as it is being loaded.
# For instance, if you wish to peform a `sleep annotation':
dt <- loadEthoscopeData(paths[1], FUN=sleepAnnotation)
# You could of course combine this with more conditions/region selection.
# For most complicated cases, you would probably have pre-generated the 
# master-table (e.g. as a csv file) before analysing the results.
}
\seealso{
\code{\link{loadEthoscopeMetaData}} To display global informations about a specific file.
}

