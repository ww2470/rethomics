% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/load-ethoscope-data.R
\name{loadEthoscopeData}
\alias{loadEthoscopeData}
\title{Read data from an ethoscope result file}
\usage{
loadEthoscopeData(what, min_time = 0, max_time = Inf,
  reference_hour = NULL, verbose = TRUE, columns = NULL, ncores = 1,
  FUN = NULL, ...)
}
\arguments{
\item{what}{Query describing which file(s) to load and, optionally,
associated variables/conditions (see details).}

\item{min_time}{Exclude data before min_time (in seconds).
This time is \emph{relative to the start of the experiment}.}

\item{max_time}{Exclude data after max_time (in seconds).
It is also relative to the start of the experiment.}

\item{reference_hour}{Hour, in the day, to use as ZT0 reference.
When unspecified, time will be relative to the start of the experiment.}

\item{verbose}{whether to print progress (a logical).}

\item{columns}{Optionnal vector of columns to be selected from the db file.
Time (t) is always implicitely selected.}

\item{ncores}{Number of cores to use for optionnal parallel processing.}

\item{FUN}{Optional function to transform the data from each \code{region_id} (i.e. a \code{data.table})
immediately after is has been loaded.}

\item{...}{Extra arguments to be passed to \code{FUN}}
}
\value{
A data.table where every row is an individual measurement.
That is a position at a unique time (\code{t}) in a
unique region (\code{region_id}), and from a unique result file/experiment (\code{experiment_id}).
The time is expressed in seconds.
Distance units (e.g. xy position, height/width) are expressed as a fraction of the width of the region
they originate from.
}
\description{
This function is used to convert all the information
contained in a result file generated by the ethoscope platform \url{http://gilestrolab.github.io/ethoscope/}
(i.e a .db file) into an \code{R} \code{data.table}.
}
\details{
\code{what} can be either a:
\itemize{
\item \strong{character vector} In which case, it is assumed that each element is the path to a different file to load.
\item \strong{data.table} to use as a \emph{query}. In which case, it \strong{must} have a column named \code{"path"}.
}

In general, you will use \link{buildEthoscopeQuery} to help you build the query.
The path basename will be used as a unique identifier for a specific experiment (\code{experiment_id}).
Generally, arbitrary column will be added to the query to map experimental conditions to file name.
In addition, the query can have a column named \code{region_id}.
When defined, only the specified combinations of \code{path} and \code{region_id} will be loaded.
This allows to map additional conditions (i.e. \code{data.table} columns) to specific \code{region_id x experiment_id}.
When additional conditions are provided,
they will result in creation of custom columns in the output of this function.
}
\examples{
\donttest{
# download the tutorial data
TUTO_DATA_URL <- paste0("https://imperialcollegelondon.box.com/shared/static/",
                        "ckr50g5yh11swmip30ivieuwavg86urb.zip")
ZIP_DATA <- tempfile(fileext=".zip")
TUTO_DATA_DIR <- tempdir()
download.file(TUTO_DATA_URL, ZIP_DATA)
unzip(ZIP_DATA, exdir= TUTO_DATA_DIR)
unlink(ZIP_DATA)
ETHOSCOPE_RESULTS_DIR <- paste(TUTO_DATA_DIR,"rethomics_tutorial_data/ethoscope/results",sep="/")
QUERY <- paste(TUTO_DATA_DIR,"rethomics_tutorial_data/ethoscope/queries/query.csv",sep="/")
# Case 1: load ALL REGIONS from a SINGLE FILE
# we can download a file from a repo:
all_db_files <- list.files(ETHOSCOPE_RESULTS_DIR, 
                          recursive = TRUE, 
                          pattern = "\\\\.db", 
                          full.names = TRUE)
one_db_file <- all_db_files[1]
print(one_db_file)
# `validation_data_file` is simply the path to the .db file in your computer
dt <- loadEthoscopeData(one_db_file)
print(dt)
# Case 2: load ALL REGIONS from MULTIPLE FILES
# we pass all the files we want to load as the `what` argument
# note that we load only three hours of data for the sake of the example
dt <- loadEthoscopeData(all_db_files,max_time = hours(3))
# Note the column `experiment_id` in dt. It tells us which file/experiment 
# each measurement originates from.
print(dt)

###############
# Case 3: load  BY REGIONS from MULTIPLE FILES AND add CONDITIONS
# In a real life scenario, you will have different treatments in several
#  machines, dates and regions. Altogether, this can be encoded in a query like:
query <- fread(QUERY)
print(query)
# In this table, each row is an individual, that is one region, in one machine, at one date/time.
# We use the folowing line to make a secondary query --
# that effectively find the path of requester files and adds it as
# new columns:
query2 <- buildEthoscopeQuery(ETHOSCOPE_RESULTS_DIR, query)
dt <- loadEthoscopeData(query2, max=hours(3))
# Note that `dt` now keeps information relative to the conditions you defined.
print(colnames(dt))
# This makes it easier to perform things such as average per treatment.
print(dt[,.(mean_x = mean(x)),by="sex"])
# We clean up (data not needed anymore):
unlink(TUTO_DATA_DIR, recursive=T)
}
}
\seealso{
\itemize{
\item \link{buildEthoscopeQuery} to generate a query with the \code{path} of the data file
\item Tutorial for this function \url{http://gilestrolab.github.io/rethomics/tutorial/todo}
\item What queries are \url{http://gilestrolab.github.io/rethomics/tutorial/todo}
\item The structure of the resuting data \url{http://gilestrolab.github.io/rethomics/tutorial/todo}
}
}
