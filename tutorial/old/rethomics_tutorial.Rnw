\documentclass{article}
\usepackage{hyperref}
\usepackage{fullpage}

\begin{document}


\title{Analyse your behavioural data with \texttt{rethomics}}
\author{Quentin Geissmann\\
\href{mailto:quentin.geissmann13@imperial.ac.uk}{quentin.geissmann13@imperial.ac.uk}\\
\\
\\
\\
\\
\\
\\
}

\maketitle

\newpage{}

<<include=FALSE>>=
library(knitr)
options(width=90)
opts_chunk$set(
concordance=TRUE,
size="footnotesize",
tidy.opts=list(blank=FALSE, width.cutoff=90),
fig.width=12, fig.height=6, fig.align='center',
warning=FALSE
)

@

\section{Installation}
\texttt{rethomics} is still under heavy development, so it cannot be uploaded to the CRAN (Comprehensive R Archive Network) -- where most stable packages are -- yet. Instead, we can install R using Hadley Wickham's popular \texttt{devtools}\footnote{installation instructions are available \href{https://github.com/hadley/devtools/blob/master/R/run-examples.r}{here}}.
Once you have \texttt{devtools} installed, it should be straightforward to install \texttt{rethomics}
<<a, eval=FALSE, echo=TRUE>>=
library(devtools)
install_github("gilestrolab/rethomics",subdir = "rethomics")
@
Check for error messages. Then, ensure the package is installed by loading it:
<<>>=
library(rethomics)
@



\section{Data structure}
In \texttt{rethomics} the goal is to store \emph{all} behavioural data in one single `data table' -- which is standard -- for subsequent statistical analysis.
In such a data table, every row correspond to a single measurement; that is the position of one animal at one time.
Every column describes a statistical variable such as t (i.e. time in second), and X and Y positions, but it can also hold information about arbitrary conditions such as treatment, sex, age, genotype and so on.

By convention:
\itemize{
\item{t, the time of a measurment, is \emph{always in seconds}}
\item{X and Y, are \emph{relative to the width of the region} they come from, and the \emph{origin is top-left}
}

For a single \textbf{experiment}, and when tracking a single animal (i.e. in a single \textbf{region}),
your data table could look like:
<<cache=TRUE>>=
data(multiple_iterative_y_mazes)
single_animal <- multiple_iterative_y_mazes[
              experiment_id == "female_FALSE_11.db"]
print(single_animal)
@

You may notice immediatly that the first few columns seem unnecessary as they have constant values.
This is because they describe variables that vary between individuals, and we have only one individual in this simplistic example.

From looking at this table, you should be able to answer:
\itemize{
\item{How many measurment have been made in this experiement?}
\item{After how many seconds was the first measurment made?, and the last?}
}

In order to understand the need for additional columns, we can load data from multiple experiments:
<<cache=TRUE>>=
data(multiple_iterative_y_mazes)
print(multiple_iterative_y_mazes)
@

Any data should \emph{always} have two columns: \textbf{experiment\_id} and \textbf{region\_id}.
Together, these columns constitue a so called \emph{key}. In other words, any unique combination of experiment \emph{and} region represents a single animal. 
As a result, we can identify unambiguously any animal given we know its region and which experiement it comes from.
Instead of using the legacy data.frames, \texttt{rethomic} takes advantage of Matt Doyle's powerful
\texttt{data.table} package\footnote{tutorial available at \url{http://user2014.stat.ucla.edu/files/tutorial\_Matt.pdf}}.
This makes it very easy and efficient to work with large amount of behavioural data.
Common operation could involve filtering data and computing variable per condition or per individual.

Let us go through several examples:
<<cache=TRUE>>=
data(multiple_iterative_y_mazes)
#We can simply call this data table `dt'
dt <- multiple_iterative_y_mazes
# keeping only females
dt_female <- dt[sex == 'female',]
# excluding any data point before 30 seconds (i.e. keeping >= 30s)
dt_currated <- dt[t >= 30,]
# Computing, per animal, the time spent in the experiment
summary_dt =  dt[,
                 .(time_spent = max(t) - min(t)),
                 by=key(dt)]
print(summary_dt)
@

Much more can be achieved using \texttt{data.table}, so I would strongly recommend to, at least, read the introduction to the 
package\footnote{\url{http://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.pdf}}.

\section{Loading data}
\subsection{Loading one file}
In this section, we will focus on loading data generated by pysolovideo\footnote{\url{https://github.com/gilestrolab/pySolo-Video}}
(i.e. \texttt{.db} files). 

A \texttt{.db} file will contain data for one experiment, that is all the animals in one monitor, from when you have clicked on `start' to when hou have clicked on `stop'. If another experiment is run later, on the same device -- or one is performed at the same time on a different device -- the data will be in another file. 

The function to load such files is called \texttt{loadPsvData}. 
It has many options, so it may be useful to \emph{read the documentation} at some stage, but for now, we will just learn how to send a `query' in order to retreive some data.
I do not expect you to have already acquired any sort of data, so we will work with some of my own
samples -- which I have enclosed within \texttt{rethomics}:

<<cache=TRUE>>=
# let us unpack these couple of files
sample_files <- c("tube_monitor_validation_subset.db",
                   "monitor_validation_subset.db")
paths <- sapply(sample_files, loadSampleData)
# the path should be unpacked in a temporary directory:
print(paths)

# The simplest case: we would like to load all the regions the first file:
dt <- loadPsvData(paths[1],verbose=F)
# We could also load all regions from all files:
dt <- loadPsvData(paths,verbose=F)
print(dt)
@

In real life, each file will have a unique name containing the date and time of the begining of the experiment as well as the name of the machine that generated it.
Therefore, file names are used as a unique identifier of the experiement (\texttt{experiment\_id}).
Often, different experiments will have different biological conditions that you should include in the resulting data table.
In order to do that, we can pass a \emph{query} to \texttt{loadPsvData}. 
A query is simply a table that has a column named \texttt{path}, and other columns for arbitrary conditions.
For instance, here we imagine that animals in the first and second experiments were treated by a control and a drug, respectively:

<<cache=TRUE>>=
query <- data.table(path=paths,
                    treatment=c("control", "drug_A"))
print(query)
@

When working with a large number of files/conditions, it would be more common to load query from a spreadsheet or a CSV file (simply use \texttt{fread} function to load data from an external CSV).
Once the query is prepared, we can simply load all the associated data:

<<cache=TRUE>>=
dt <- loadPsvData(query,verbose=F)
print(dt)
@

Importantly, there is now a column named `treatment' in your data. 
This means you can conveniently study differences explained by that variable.
This would have been very useful if, for instance, you had done 50 experiments where you have changed both sex and genotype, and want to investigate the effect of these variables on a behavioural variable (e.g. amount of sleep).

\subsection{Different conditions per \texttt{region\_id}}
In some cases, you may want to load only specific regions, or you may have different conditions (in different regions) within the same experiment.
If you add a column in your query called \texttt{region\_id}, only specified regions will be loaded (as opposed to all regions in the previous example).

<<cache=TRUE>>=
query <- data.table(path=paths, 
                    treatment=c("control", "drug_A"), 
                    region_id=rep(1:10,each= 2))

# We make a dummy query where we imagine that 
# every other region contains a female individual
query[, sex := ifelse(region_id %% 2, "male", "female" )]                    

# Note that we load only regions lower than twenty
print(query)
# Now we can use our query
dt <- loadPsvData(query,verbose=F)
print(dt)
@

Note that there were some warnings, this is because some of the requested regions are not in the example data. 
Indeed, I only provided a small subset of available regions in order to reduce the size of the sample.
Also, as before, our data table(\texttt{dt}) has additional columns for the conditions we added.

As a heads-up, lets see how one would use data.table syntax to compute median x position per sex and treatment:

<<cache=TRUE>>=
summary <- dt[, .(median_x = median(x)),
                by=c("sex","treatment")]
print(summary)
@

\subsection{Automaticaly find your experiment files}
In some cases, you will have downloaded your \texttt{.db} files (e.g. on a memory stick), but more likely, they will be stored in a synchronised network drive.
In the latter case, it will be tedious to locate your file one by one. 
In real live, you will know where is the network drive folder where the data is saved, when (i.e. at what date) you \emph{started} your experiment (this is the date you clicked on start), and which device you have used.
Using the function \texttt{fetchPsvResultFiles}, you can use this information to retrieve the paths of your \texttt{.db} files automatically.
If you want to list/retrieve \emph{all} available experiments/files, you can do:

<<eval=TRUE, echo=TRUE,cache=TRUE>>=
# You will need to change this
YOUR_RESULT_DIR <- '/data/psv_results'
all_files <- fetchPsvResultFiles(YOUR_RESULT_DIR)
print(all_files[,.(file,date,machine_name)])
@

\texttt{YOUR\_RESULT\_DIR} is where ever your \texttt{psv\_results} directory (i.e. folder) is on your computer, or on the network.
More importantly you can also generate a query (i.e. table) in which you request experiments by \texttt{date} and a \texttt{machine\_name}. It is crucial that the query has columns \emph{exactly named} \texttt{date} and \texttt{machine\_name}:

<< eval=FALSE, echo=TRUE>>=
# we want two experiments performed the same day (2015-06-02),
# in two different machines "GGSM-001" and "GGSM-003":

query <- data.table(date="2015-06-05",
                   machine_name=c("GGSM-001","GGSM-003", "GGSM-004"),
                   condition=c("A", "B","C"))
# Note that I added an extra column to map an experimental condition:
print(query)
 
map <- fetchPsvResultFiles(YOUR_RESULT_DIR, query)
# This should be able to find the requested files, if they exist.
print(map)

# Importantly, the added condition is still there, 
# so we can simply send this map to loadPsvData:
dt <- loadPsvData(map)
@

% << eval=FALSE, echo=FALSE>>=
% query <- data.table(date="2015-06-05",
%                    machine_name=c("GGSM-001","GGSM-003", "GGSM-004"),
%                    condition=c("A", "B","C"))
% map <- fetchPsvResultFiles(YOUR_RESULT_DIR, query)
% dt <- loadPsvData(map)
% @

It is possible that you have performed several experiments the same day.
If the date is ambiguous, \emph{the latest experiment} will be returned (and a warning is displayed).
You can also specify the date as `2015-06-02\_hh-mm-ss', which is unambiguous.

 
\subsection{Analysing data}

\subsection{Sleep annotation}
Now we know how to load data, I will use preloaded sleep-annotated data in the package.
The \texttt{sleep\_male\_vs\_females} data is a set of three experiments....
\subsection{Visualisation}
This is the exciting part!
Let us focus on sleep, and use \texttt{sleep\_male\_vs\_females} dataset.
In a first place, you will generally want to plot a rough profile for \emph{each individual} in order to quality control animals.
This could, for instance, reveal unexpected abnormalities (e.g. dead animal, arrithmicity,...).
This is precisely the purpose of the overview plot.
\subsubsection{Overview plot}
\texttt{sleep\_male\_vs\_females} has been annotated and contains a variable called `maximal velocity', which is a measure of activity.
In addition is as a variable named `asleep', which is `TRUE' when the animal is scored as sleeping, and `FALSE' otherwise.

Let us have a look at how activity varies over time for each individual:
<<>>=
data(sleep_male_vs_females)
# We just rename this variable
my_data <- sleep_male_vs_females
pl <- overviewPlot(max_velocity,my_data)
print(pl)
@

The colour intensity is proportional to the value of \texttt{max\_velocity}. As expected, there is a sharp period of activity between day and night transitions (12h,24h,32h,..).


We can also look at the average sleep. This time though, 
we would like to group rows by sex to see if we can see any obvious population trend.
we can specify that by setting `condition' to `sex'
<<>>=
data(tube_monitor_validation)
pl <- overviewPlot(asleep,my_data,condition=sex)
print(pl)
@

All built in visualisation functions decribed here will produce a ggplot\footnote{\url{http://ggplot2.org/book/}} object, which you can easyly modify (e.g. change title, axis names, draw arrows.... ). 
As an example, we can draw a doted line at 12h (0.5 days).

<<>>=
pl <- pl + geom_vline(aes(xintercept=c(0.5)),linetype=2,size=2)
print(pl)
@

\subsubsection{Ethograms}

Most of the time, after having check the quality of your data, you will want to see difference between population, over time.
Ethograms represent a chosen y variable and will group data, on the x axis, by time window (the default is 30min):

<<>>=
pl <- ethogramPlot(asleep, my_data)
print(pl)
@

We can also add some error bar:

<<>>=
pl <- ethogramPlot(asleep,my_data,error_bar="sem")
print(pl)
@

Much like with the \texttt{overviewPlot} function, we can select a group. For instance, we group per sex:
<<>>=
pl <- ethogramPlot(asleep,my_data,condition=sex,error_bar="sem")
print(pl)
@


\end{document}

