\documentclass{article}
\usepackage{hyperref}

\begin{document}
\SweaveOpts{concordance=TRUE}
\section{Installation}
\texttt{rethomics} is still under heavy development, so it cannot be uploaded to the CRAN (Comprehensive R Archive Network) -- where most stable packages are -- yet. Instead, we can install R using Hadley Wickham's popular \texttt{devtools}\footnote{installation instructions are available \href{https://github.com/hadley/devtools/blob/master/R/run-examples.r}{here}}.
Once you have \texttt{devtools} installed, it should be straightforward to install \texttt{rethomics}
<<a, eval=FALSE, echo=TRUE>>=
library(devtools)
install_github("gilestrolab/rethomics",subdir = "rethomics")
@
Check for error messages. Then, ensure the package is installed by loading it:
<<>>=
library(rethomics)
@

\section{Loading data}

\subsection{Data structure}
In \texttt{rethomics} the goal is to store \emph{all} the behavioural data in one single dataframe, which is standard for subsequent statistical analysis.
In such a dataframe, every row correspond to a single measurement; that is he position of one animal at one time.
Every column describes a statistical variable such as t, and X and Y positions, but they can also hold 
information about arbitrary conditions such as treatment, sex, age, genotype and so on.

By convention:
\itemize{
\item{t, the variable holding the time, is always \emph{in seconds}}
\item{X and Y, are \emph{relative to the width of the region} they come from, and the \emph{origin is top-left}
}

For a single \textbf{experiment}, and when tracking a single animal (i.e. in a single \textbf{region}),
your data table could look like:
<<>>=
library(rethomics)
data(multiple_iterative_y_mazes)
single_animal <- multiple_iterative_y_mazes[
              experiment_id == "female_FALSE_11.db"]
print(single_animal)
@

The first thing you may notice is that the first few columns seem unnecessary as they have constant values.
This is because they describe variables that vary between individuals, and we have only one individual.

In order to understand the need for additional columns, we can load data from multiple experiments:
<<>>=
library(rethomics)
data(multiple_iterative_y_mazes)
print(multiple_iterative_y_mazes)
@

The data will \emph{always} have two columns: \textbf{experiment\_id} and \textbf{region\_id}.
Together, these columns form a \emph{key}, that is combinations of experiment \emph{and} region represent unique animals. in other words, we can identify, unambiguously, any animal from its region and experiment identifier.
Instead of using the legacy data.frames, \texttt{rethomic} takes advantage of Matt Doyle's powerful \texttt{data.table} package\footnote{tutorial available at \url{http://user2014.stat.ucla.edu/files/tutorial\_Matt.pdf}}.
This makes it very easy and efficient to work with large amount of behavioural data.
Common operation could involve filtering data and computing variable per condition or per individual.
Let us go through several examples:
<<>>=
library(rethomics)
data(multiple_iterative_y_mazes)
#We can simply call this data table `dt'
dt <- multiple_iterative_y_mazes
# keeping only females
dt_female <- dt[sex == 'female',]
# excluding any data point before 30 secondes (i.e. keeping >= 30s)
dt_currated <- dt[t >= 30,]
# Computing, per animal, the time spent in the experiment
summary_dt =  dt[,.(time_spent = max(t) - min(t)),
                by=key(dt)]
print(summary_dt)
@
Much more can be achieved using \texttt{data.table}, so I would strongly recommend to, at least, read the package introduction\footnote{\url{http://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.pdf}}.


\subsection{Loading one file}
In this section, we will focus on loading data generated by pysolovideo\footnote{\url{https://github.com/gilestrolab/pySolo-Video}} (i.e. \texttt{.db} files).
In other words, we would like to load the data in the \texttt{.db} file as a data table structure such as the ones we described above.
The function to load these data is called \texttt{loadPsvData}. It has many options, so it may be useful to read the documentation at some stage, but for now, we will just learn how to send a `query' to obtain some data.
I do not expect you to have already acquired any sort of data, so we will work with some of my samples, which I have enclosed within \texttt{rethomics}:

<<>>=
# let us unpack these couple of files
sample_files <- c("tube_monitor_validation_subset.db",
                   "monitor_validation_subset.db")
paths <- sapply(sample_files, loadSampleData)
# the path should be unpacked in a temporary directory:
print(paths)

# The simplest case: we would like to load all the regions the first file:
dt <- loadPsvData(paths[1],verbose=F)
# We could also load all regions from all files:
dt <- loadPsvData(paths,verbose=F)
@

Often, each file will correspond for a different condition (or combination of variables)
that you would like to include in the resulting data table. In order to do that, we can pass a \emph{query} to \texttt{loadPsvData}.
a query is simply a table that has a column named \texttt{path}, and other columns for arbitrary conditions:

<<>>=
query <- data.table(path=paths,
                    treatment=c("control", "drug_A"))
print(query)
@

When working with a large number of files/conditions, it would be more common to load query from a spreadsheet/CSV file.
One the query is prepared, we can simply load all the associated data:

<<>>=
dt <- loadPsvData(query,verbose=F)
print(dt)
@

Importantly, there is now a column named `treatment' in your data. This means you can then conveniently study differences explained by that variable.
You could imagine a scenario where you have done 50 experiments where you have changed both sex and genotype, and want to explain behavioural changes with these variables.

\subsection{Fancier queries}
In some cases, you may want to load only specific regions, and even add different conditions per region, within the same experiment.
If you add a column in your query called \texttt{region\_id}, only specified regions will be loaded (as opposed to all regions in the previous example).
<<>>=
query <- data.table(path=paths, 
                    treatment=c("control", "drug_A"), 
                    region_id=rep(1:20,each= 2))

# We make a dummy query where  we imagine that 
# every other reagion contains a female individual
query[, sex := ifelse(region_id %% 2, "male", "female" )]                    

# Note that we load only regions lower than twenty

# Now we can use our query
dt <- loadPsvData(query,verbose=F)
print(dt)
@
Note that there were some warnings, this is because some of the requested regions are not in the example data. 
Indeed, I only provided a small subset of available regions in order to reduce the size of the samples.
Also, as before, our data table(\texttt{dt}) has additional columns for the conditions we added.

As a heads-up, lets see how one would use data table syntax to compute median x position per sex and treatment:

<<>>=
summary <- dt[, .(median_x = median(x)),
                by=c(key(dt),"sex")]
print(summary)
@

% \subsection{Loading from network drive}
% Now, this is great when you know where you \texttt{.db} files are, but in real life, they may be stored by \texttt{pysolovideo} in a network drive, and you cannot retrieve their locations easily.
% What you know however, is when (at what date) you started your experiment, and which device you have used.
% Using the function \texttt{fetchPsvResultFiles}, you can retrieve data from the directory structure.
% If you want to list/retrieve all available experiments/files, you can do:
% 
% <<eval=FALSE, echo=TRUE>>=
% fetchPsvResultFiles(YOUR_RESULT_DIR)
% @
% 
% \texttt{YOUR\_RESULT\_DIR} is where ever your \texttt{psv\_results} directory is on your computer, or on the network.
% You can also generate a query (table) where you request experiments by \texttt{date} and a \texttt{machine_name}.
% It is important that the query has columns exactly named \texttt{date} and \texttt{machine_name}:
% 
% << eval=FALSE, echo=TRUE>>=
% # we want two experiments performed the same day (2015-06-02),
% # in two different machines "GGSM-001" and "GGSM-003":
% 
% query <- data.table(date="2015-06-02",
%                     machine_name=c("GGSM-001","GGSM-003"),
%                     genotype=c("A", "B"))
% # Note that I added an extra column to map an experimental condition:
% print(query)
% 
% map <- fetchPsvResultFiles(MY_DATA_DIR, query)
% # This should be able to find the requested files, if they exist.
% print(map)
% 
% # Importantly, the added condition is still there, 
% # so we can simply send this map to loadPsvData:
% dt <- loadPsvData(map)
% @
% It is possible that you have performed several experiments the same day.
% If the date is ambiguous, \emph{the latest experiment} will be returned (and a warning is displayed).
% You can also specify the date as `2015-06-02_hh-mm-ss', which should be unambiguous.
% 
% 
% \subsection{Analysing data}
% \subsection{Sleep annotation}
\subsection{Visualisation}
This is the exciting part! Now we know how to load data, I will use preloaded data in the package.
The \texttt{tube\_monitor\_validation} data set is one experiement with 20 regions.
We would like to have an overview of the activity in each region as a graphical quality control:
<<fig=TRUE>>=
data(tube_monitor_validation)
# we make a sleep annotation, for ach animal. this will 
# also compute maximal velocity for every chunk of 10s
my_data <- tube_monitor_validation[,sleepAnnotation(.SD),
                                    by=key(tube_monitor_validation)]
pl<- overviewPlot(max_velocity,my_data)
print(pl)
@

<<fig=TRUE>>=
pl <- pl + geom_vline(aes(xintercept=c(0.5)),linetype=2,size=3)
print(pl)
@

% \subsubsection{Overview plot}
% \subsubsection{Ethograms}
% \subsection{Bout analysis}
% 


\end{document}